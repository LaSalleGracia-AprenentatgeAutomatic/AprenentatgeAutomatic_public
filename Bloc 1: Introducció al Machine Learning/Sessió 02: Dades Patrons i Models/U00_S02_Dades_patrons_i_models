ğŸ§© SessiÃ³ 2 â€” Dades, patrons i models (2 h)

RAs treballats: 1 i 2
Durada: 2 h (una sessiÃ³ de classe)
Objectiu general:
Fer entendre als alumnes com un model pot detectar patrons a partir de dades, com es mesura lâ€™error i com sâ€™ajusten els parÃ metres dâ€™un model senzill.

ğŸ§  Objectius especÃ­fics

Comprendre el concepte dâ€™error i funciÃ³ de cost.

Visualitzar com canvia lâ€™error quan es modifica un model (una lÃ­nia).

ReconÃ¨ixer la diferÃ¨ncia entre patrons humans i patrons matemÃ tics.

Introduir la idea dâ€™ajust del model (sense fer derivades encara).

Fomentar la curiositat sobre com aprÃ¨n una mÃ quina.

ğŸ—ï¸ Estructura de la sessiÃ³
ğŸ”¹ 1ï¸âƒ£ RepÃ s i connexiÃ³ amb la sessiÃ³ anterior (15 min)

Objectiu: assegurar que tots recorden els conceptes clau: dades, vectors i matrius.

Activitat curta:

Mostra el dataset dâ€™alÃ§ada, pes i esportistes (versiÃ³ no lineal).

Pregunta:

â€œQuÃ¨ ens diuen aquestes dades?â€

â€œSi posÃ©ssim una lÃ­nia al mig, separaria bÃ© els esportistes?â€

â€œQuÃ¨ passa amb els punts que queden entre mig?â€

ConclusiÃ³: no Ã©s trivial; cal una manera matemÃ tica de quantificar â€œcom dâ€™encertatsâ€ som.

ğŸ”¹ 2ï¸âƒ£ Mini repÃ s matemÃ tic contextualitzat (30 min)

Objectiu: entendre quÃ¨ Ã©s lâ€™error i com es pot resumir en una funciÃ³ de cost.

ğŸ§® Conceptes a introduir

PredicciÃ³ (Å·) vs Valor real (y)

Error: e = y - Å·

Error absolut i error quadrÃ tic

Mitjana dels errors (MSE: Mean Squared Error)

ğŸ’» Exemple amb Python
import numpy as np
import matplotlib.pyplot as plt

# Dades simples (exemple d'alÃ§ada - pes)
X = np.array([1.60, 1.65, 1.70, 1.75, 1.80])
y = np.array([55, 60, 65, 70, 76])   # valors reals
y_pred = np.array([58, 63, 67, 69, 73])  # predicciÃ³ d'un model simple

errors = y - y_pred
mse = np.mean(errors**2)

plt.scatter(X, y, label='Valors reals')
plt.plot(X, y_pred, color='orange', label='PredicciÃ³')
plt.legend()
plt.title(f'Error quadrÃ tic mig (MSE) = {mse:.2f}')
plt.xlabel("AlÃ§ada (m)")
plt.ylabel("Pes (kg)")
plt.show()


ReflexiÃ³ guiada:

Si canviem la lÃ­nia (la predicciÃ³), lâ€™error canvia.

El model â€œaprÃ¨nâ€ buscant la lÃ­nia que minimitza aquest error.

Sense derivades: imagina que provem moltes lÃ­nies i ens quedem amb la que tÃ© lâ€™error mÃ©s petit.

ğŸ”¹ 3ï¸âƒ£ Activitat aplicada: Juguem a ser el model (45 min)

Objectiu: entendre quÃ¨ vol dir â€œajustar un modelâ€ mitjanÃ§ant prova i error.

Metodologia: simulaciÃ³ prÃ ctica amb dades visuals.

Mostra el grÃ fic â€œAlÃ§ada vs Pesâ€ (dataset complet de 20 persones).

Demana als alumnes que traquin una lÃ­nia recta a mÃ  (amb llapis o al grÃ fic projectat) que â€œsepariâ€ esportistes de no esportistes o que â€œajustiâ€ el pes.

Calcula amb Python lâ€™error de cada proposta.

ğŸ’» Exemple interactiu (professor)
import numpy as np
import matplotlib.pyplot as plt

# Exemple de dues lÃ­nies candidates
X = np.linspace(1.55, 1.95, 100)
model1 = 30 + 25 * X    # lÃ­nia 1
model2 = 40 + 20 * X    # lÃ­nia 2

plt.scatter(df['AlÃ§ada_m'], df['Pes_kg'], c=df['Esportista'], cmap='coolwarm', label='Dades reals')
plt.plot(X, model1, label='Model 1')
plt.plot(X, model2, label='Model 2')
plt.legend()
plt.xlabel('AlÃ§ada (m)')
plt.ylabel('Pes (kg)')
plt.title('Comparant models visuals')
plt.show()


DiscussiÃ³:

Quin model â€œencaixa millorâ€?

Si fÃ³ssim la mÃ quina, com podrÃ­em decidir-ho matemÃ ticament?

Com podem saber quan parar dâ€™ajustar?

ğŸ‘‰ ConclusiÃ³: aixÃ² Ã©s el que fa lâ€™algorisme dâ€™aprenentatge: canvia els parÃ metres per reduir lâ€™error.

ğŸ”¹ 4ï¸âƒ£ Tancament i reflexiÃ³ (15 min)

Preguntes per consolidar:

QuÃ¨ Ã©s una funciÃ³ de cost?

Com sap una mÃ quina si estÃ  millorant?

QuÃ¨ diferencia un model â€œajustatâ€ dâ€™un que â€œmemoritzariaâ€ els exemples?

QuÃ¨ creieu que passa si hi ha massa variables?

Missatge final:

Lâ€™aprenentatge automÃ tic consisteix a trobar els parÃ metres del model que minimitzen lâ€™error sobre les dades.
El proper pas (Bloc 1) Ã©s veure com sâ€™aprÃ¨n aquest ajust pas a pas: la regressiÃ³ supervisada.

ğŸ§¾ Materials necessaris

Notebook o script amb el dataset del Bloc 0 (no lineal).

Projector o pissarra digital per dibuixar lÃ­nies i comparar errors.

Paper i bolÃ­graf per lâ€™activitat â€œtraÃ§a la teva lÃ­niaâ€.

CÃ lculs visuals dâ€™error amb Python (ja preparats pel docent).

ğŸ¯ Resultats esperats

En acabar la sessiÃ³, lâ€™alumne:

EntÃ©n el concepte de funciÃ³ de cost (error mitjÃ ).

Sap que lâ€™aprenentatge Ã©s un procÃ©s iteratiu dâ€™ajust.

Pot raonar perquÃ¨ una lÃ­nia pot funcionar millor que una altra.

TÃ© curiositat per saber com sâ€™automatitza aquest procÃ©s (gradient descendent).


Valors soluciÃ³:     #a_hat, b_hat = 24.965, 20.052
    #print(f'a = {a_hat}, b = {b_hat}')